{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "05d904f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados carregados com sucesso. Primeiras 5 linhas:\n",
      "         data      unidade      material   tipo  quantidade responsavel\n",
      "0  2025-01-12  Santo Amaro          Tubo  saida        -5.0     Vincent\n",
      "1  2025-03-14        Moema       Seringa  saida        -3.0       Mason\n",
      "2  2025-02-09  Santo Amaro       Seringa  saida        -5.0     Kenneth\n",
      "3  2025-03-23  Santo Amaro       Seringa  saida       -14.0     Jeffrey\n",
      "4  2024-12-13      Morumbi  Medicamentos  saida       -10.0      Robert\n",
      "\n",
      "Variável 'ATRASO_ENTREGA' criada: 1 se CONSUMO_REAL > 230.50 (Top 25% de Consumo).\n",
      "  unidade      material  CONSUMO_REAL  qtd_transacoes  media_transacao  \\\n",
      "0   Moema   Esparadrapo          62.0               7         8.857143   \n",
      "1   Moema          Gaze          92.0               7        13.142857   \n",
      "2   Moema  Medicamentos         100.0               8        12.500000   \n",
      "3   Moema       Seringa          80.0               8        10.000000   \n",
      "4   Moema          Tubo         278.0               7        39.714286   \n",
      "\n",
      "   ATRASO_ENTREGA  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               1  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression, Ridge, Lasso, LinearRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, mean_squared_error, r2_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Configuração de exibição\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Carregamento e Engenharia de Features\n",
    "try:\n",
    "    df_raw = pd.read_csv('dados_consumo_simulados.csv')\n",
    "    print(\"Dados carregados com sucesso. Primeiras 5 linhas:\")\n",
    "    print(df_raw.head())\n",
    "\n",
    "    # --- Pré-processamento e Engenharia de Features ---\n",
    "\n",
    "    # 1. Limpeza/Cálculo de Quantidade Absoluta (Se 'quantidade' é o valor do consumo/estoque)\n",
    "    # Assumimos que o problema se refere à gestão de estoque/consumo por Unidade e Material\n",
    "    df_raw['quantidade_abs'] = df_raw['quantidade'].abs()\n",
    "\n",
    "    # 2. Criação da Variável Alvo Contínua (Regressão)\n",
    "    # Exemplo: Consumo Total Mínimo do Material\n",
    "    df_agg = df_raw.groupby(['unidade', 'material']).agg(\n",
    "        CONSUMO_REAL=('quantidade_abs', 'sum'),\n",
    "        qtd_transacoes=('quantidade_abs', 'count'),\n",
    "        media_transacao=('quantidade_abs', 'mean')\n",
    "    ).reset_index()\n",
    "\n",
    "    # 3. Criação da Variável Alvo Binária (Classificação)\n",
    "    # Problema: Atraso na Entrega/Necessidade Crítica (ex: alto consumo).\n",
    "    # Vamos simular o 'ATRASO_ENTREGA' para as unidades/materiais com consumo acima do 75º percentil.\n",
    "    consumo_q75 = df_agg['CONSUMO_REAL'].quantile(0.75)\n",
    "    df_agg['ATRASO_ENTREGA'] = (df_agg['CONSUMO_REAL'] > consumo_q75).astype(int)\n",
    "    print(f\"\\nVariável 'ATRASO_ENTREGA' criada: 1 se CONSUMO_REAL > {consumo_q75:.2f} (Top 25% de Consumo).\")\n",
    "    print(df_agg.head())\n",
    "\n",
    "    # 4. Preparação das Features para Modelagem (One-Hot Encoding)\n",
    "    X = df_agg.drop(columns=['CONSUMO_REAL', 'ATRASO_ENTREGA'])\n",
    "    y_class = df_agg['ATRASO_ENTREGA']\n",
    "    y_reg = df_agg['CONSUMO_REAL']\n",
    "\n",
    "    # Separando features categóricas e numéricas para pré-processamento\n",
    "    categorical_features = ['unidade', 'material']\n",
    "    numerical_features = ['qtd_transacoes', 'media_transacao']\n",
    "\n",
    "    # Criação do Preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', StandardScaler(), numerical_features),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    # Aplicação do Preprocessor e Divisão dos Dados\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    feature_names = numerical_features + list(preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_features))\n",
    "    X_df = pd.DataFrame(X_processed, columns=feature_names)\n",
    "\n",
    "    # Divisão para Classificação\n",
    "    X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(\n",
    "        X_df, y_class, test_size=0.3, random_state=42, stratify=y_class\n",
    "    )\n",
    "    # Divisão para Regressão (usamos os mesmos X_df e y_reg)\n",
    "    X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "        X_df, y_reg, test_size=0.3, random_state=42\n",
    "    )\n",
    "    features = feature_names # Atualiza a lista de features para o código de modelagem\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"Erro: O arquivo 'dados_consumo_simulados(2).csv' não foi encontrado. Verifique o caminho.\")\n",
    "    # Adicione `return` se quiser parar a execução em caso de erro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d9374053",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando cv=3 (mínimo de amostras por classe = 3)\n",
      "O melhor valor de K encontrado é: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 7, n_samples_fit = 6, n_samples = 4\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 6, n_samples = 4\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 8, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 9, n_samples_fit = 6, n_samples = 4\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 9, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 9, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 6, n_samples = 4\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:971: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 152, in __call__\n",
      "    score = scorer._score(\n",
      "        cached_call, estimator, *args, **routed_params.get(name).score\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 400, in _score\n",
      "    y_pred = method_caller(\n",
      "        estimator,\n",
      "    ...<2 lines>...\n",
      "        pos_label=pos_label,\n",
      "    )\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_scorer.py\", line 90, in _cached_call\n",
      "    result, _ = _get_response_values(\n",
      "                ~~~~~~~~~~~~~~~~~~~~^\n",
      "        estimator, *args, response_method=response_method, **kwargs\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_response.py\", line 214, in _get_response_values\n",
      "    y_pred = prediction_method(X)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_classification.py\", line 274, in predict\n",
      "    neigh_ind = self.kneighbors(X, return_distance=False)\n",
      "  File \"c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\neighbors\\_base.py\", line 854, in kneighbors\n",
      "    raise ValueError(\n",
      "    ...<3 lines>...\n",
      "    )\n",
      "ValueError: Expected n_neighbors <= n_samples_fit, but n_neighbors = 10, n_samples_fit = 7, n_samples = 3\n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class_counts = pd.Series(y_train_class).value_counts()\n",
    "min_class_count = class_counts.min()\n",
    "cv_value = min(5, min_class_count)  # se alguma classe tem <5, ajusta automaticamente\n",
    "if cv_value < 2:\n",
    "    cv_value = 2  # mínimo de 2 folds para não quebrar\n",
    "\n",
    "print(f\"Usando cv={cv_value} (mínimo de amostras por classe = {min_class_count})\")\n",
    "\n",
    "# Define o intervalo seguro de K\n",
    "max_k = min(15, len(X_train_class))\n",
    "k_range = range(1, max_k + 1)\n",
    "k_scores = []\n",
    "\n",
    "for k in k_range:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn, X_train_class, y_train_class, cv=cv_value, scoring='accuracy')\n",
    "    k_scores.append(scores.mean())\n",
    "\n",
    "best_k = k_range[np.argmax(k_scores)]\n",
    "print(f\"O melhor valor de K encontrado é: {best_k}\")\n",
    "\n",
    "# Treina modelo final\n",
    "knn_model = KNeighborsClassifier(n_neighbors=best_k)\n",
    "knn_model.fit(X_train_class, y_train_class)\n",
    "y_pred_knn = knn_model.predict(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9928db2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Métricas de Avaliação KNN ---\n",
      "Acurácia: 0.8000\n",
      "Precisão: 0.0000\n",
      "Recall: 0.0000\n",
      "F1-Score: 0.0000\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[4 0]\n",
      " [1 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "acc_knn = accuracy_score(y_test_class, y_pred_knn)\n",
    "prec_knn = precision_score(y_test_class, y_pred_knn)\n",
    "rec_knn = recall_score(y_test_class, y_pred_knn)\n",
    "f1_knn = f1_score(y_test_class, y_pred_knn)\n",
    "\n",
    "print(\"\\n--- Métricas de Avaliação KNN ---\")\n",
    "print(f\"Acurácia: {acc_knn:.4f}\")\n",
    "print(f\"Precisão: {prec_knn:.4f}\")\n",
    "print(f\"Recall: {rec_knn:.4f}\")\n",
    "print(f\"F1-Score: {f1_knn:.4f}\")\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(confusion_matrix(y_test_class, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2090171a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Interpretação dos Coeficientes da Regressão Logística ---\n",
      "                 Feature  Coeficiente  Odds Ratio (exp(Coef))\n",
      "0        media_transacao     1.090927                2.977034\n",
      "1          material_Tubo     0.407947                1.503728\n",
      "2         qtd_transacoes     0.180855                1.198241\n",
      "3       material_Seringa     0.090370                1.094579\n",
      "4        unidade_Morumbi     0.017999                1.018162\n",
      "5          unidade_Moema    -0.107783                0.897822\n",
      "6  material_Medicamentos    -0.123978                0.883399\n",
      "7   material_Esparadrapo    -0.255017                0.774904\n",
      "8    unidade_Santo Amaro    -0.394649                0.673917\n",
      "9          material_Gaze    -0.603755                0.546754\n",
      "\n",
      "Interpretação:\n",
      "Features com Odds Ratio (OR) > 1 aumentam a chance de 'ATRASO_ENTREGA'.\n",
      "Features com OR < 1 diminuem a chance de 'ATRASO_ENTREGA'.\n"
     ]
    }
   ],
   "source": [
    "# Modelo de Regressão Logística\n",
    "logreg_model = LogisticRegression(solver='liblinear', random_state=42)\n",
    "logreg_model.fit(X_train_class, y_train_class)\n",
    "y_pred_logreg = logreg_model.predict(X_test_class)\n",
    "\n",
    "# Interpretação dos Coeficientes\n",
    "print(\"\\n--- Interpretação dos Coeficientes da Regressão Logística ---\")\n",
    "coef_df = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Coeficiente': logreg_model.coef_[0],\n",
    "    'Odds Ratio (exp(Coef))': np.exp(logreg_model.coef_[0])\n",
    "})\n",
    "coef_df = coef_df.sort_values(by='Odds Ratio (exp(Coef))', ascending=False).reset_index(drop=True)\n",
    "print(coef_df.head(10)) # Exibe as 10 mais relevantes\n",
    "\n",
    "# Interpretação\n",
    "print(\"\\nInterpretação:\")\n",
    "print(\"Features com Odds Ratio (OR) > 1 aumentam a chance de 'ATRASO_ENTREGA'.\")\n",
    "print(\"Features com OR < 1 diminuem a chance de 'ATRASO_ENTREGA'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0ce36443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparação de Métricas de Classificação (KNN vs. LogReg) ---\n",
      "                     Acurácia  F1-Score\n",
      "Modelo                                 \n",
      "KNN                       0.8  0.000000\n",
      "Regressão Logística       0.8  0.666667\n",
      "\n",
      "Discussão - Vantagens:\n",
      "KNN: Bom para fronteiras complexas, mas 'caixa preta'.\n",
      "Regressão Logística: Oferece interpretabilidade via Odds Ratios, ideal para entender a influência de cada material/unidade no risco de atraso.\n"
     ]
    }
   ],
   "source": [
    "acc_logreg = accuracy_score(y_test_class, y_pred_logreg)\n",
    "prec_logreg = precision_score(y_test_class, y_pred_logreg)\n",
    "rec_logreg = recall_score(y_test_class, y_pred_logreg)\n",
    "f1_logreg = f1_score(y_test_class, y_pred_logreg)\n",
    "\n",
    "comparacao_class = pd.DataFrame({\n",
    "    'Modelo': ['KNN', 'Regressão Logística'],\n",
    "    'Acurácia': [acc_knn, acc_logreg],\n",
    "    'F1-Score': [f1_knn, f1_logreg]\n",
    "}).set_index('Modelo')\n",
    "\n",
    "print(\"\\n--- Comparação de Métricas de Classificação (KNN vs. LogReg) ---\")\n",
    "print(comparacao_class)\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Vantagens:\")\n",
    "print(\"KNN: Bom para fronteiras complexas, mas 'caixa preta'.\")\n",
    "print(\"Regressão Logística: Oferece interpretabilidade via Odds Ratios, ideal para entender a influência de cada material/unidade no risco de atraso.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ff47e8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparação de Coeficientes: Regressão Linear vs. Ridge (Alpha=1.0) ---\n",
      "                Feature  Linear_Reg_Coef  Ridge_Coef\n",
      "1       media_transacao       196.142184  149.671401\n",
      "5  material_Esparadrapo       141.863962   -5.366169\n",
      "0        qtd_transacoes       115.395632   56.598256\n",
      "3       unidade_Morumbi        15.312623  -15.403642\n",
      "2         unidade_Moema        15.160556  -15.318069\n",
      "\n",
      "Discussão - Efeito da Regularização Ridge:\n",
      "Ridge encolhe a magnitude dos coeficientes, mas não os zera. Isso estabiliza o modelo, prevenindo que features pouco importantes dominem, sem eliminá-las.\n"
     ]
    }
   ],
   "source": [
    "# Modelo de Regressão Linear Simples (Base)\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Modelo Ridge (L2 Regularization)\n",
    "alpha_ridge = 1.0 # Exemplo de Alpha\n",
    "ridge_model = Ridge(alpha=alpha_ridge)\n",
    "ridge_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Comparação dos Coeficientes\n",
    "coef_comp_reg = pd.DataFrame({\n",
    "    'Feature': features,\n",
    "    'Linear_Reg_Coef': lin_reg.coef_,\n",
    "    'Ridge_Coef': ridge_model.coef_\n",
    "})\n",
    "\n",
    "print(f\"\\n--- Comparação de Coeficientes: Regressão Linear vs. Ridge (Alpha={alpha_ridge}) ---\")\n",
    "print(coef_comp_reg.sort_values(by='Linear_Reg_Coef', ascending=False).head(5))\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Efeito da Regularização Ridge:\")\n",
    "print(\"Ridge encolhe a magnitude dos coeficientes, mas não os zera. Isso estabiliza o modelo, prevenindo que features pouco importantes dominem, sem eliminá-las.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d8f3e688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparação de Coeficientes: Ridge vs. Lasso (Alpha=1.0) ---\n",
      "                 Feature  Linear_Reg_Coef  Ridge_Coef  Lasso_Coef\n",
      "1        media_transacao       196.142184  149.671401  175.579551\n",
      "5   material_Esparadrapo       141.863962   -5.366169   65.098306\n",
      "0         qtd_transacoes       115.395632   56.598256   85.210906\n",
      "3        unidade_Morumbi        15.312623  -15.403642   -0.561587\n",
      "2          unidade_Moema        15.160556  -15.318069    0.000000\n",
      "6          material_Gaze        -8.088632  -15.958650   -0.000000\n",
      "4    unidade_Santo Amaro       -30.473179   30.721711    7.576456\n",
      "9          material_Tubo       -34.478796   13.091449    0.000000\n",
      "8       material_Seringa       -49.583840    8.984384   -0.000000\n",
      "7  material_Medicamentos       -49.712695   -0.751014  -10.174618\n",
      "\n",
      "Discussão - Efeito da Regularização Lasso:\n",
      "Lasso zera coeficientes de features irrelevantes (seleção automática de variáveis).\n",
      "Variáveis excluídas (Coeficiente ~ 0) pelo Lasso: 4 variáveis.\n"
     ]
    }
   ],
   "source": [
    "# Modelo Lasso (L1 Regularization)\n",
    "alpha_lasso = 1.0 # Valor pode ser ajustado. Um valor maior força mais zeros.\n",
    "lasso_model = Lasso(alpha=alpha_lasso, max_iter=10000)\n",
    "lasso_model.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "# Comparação dos Coeficientes\n",
    "coef_comp_reg['Lasso_Coef'] = lasso_model.coef_\n",
    "\n",
    "print(f\"\\n--- Comparação de Coeficientes: Ridge vs. Lasso (Alpha={alpha_lasso}) ---\")\n",
    "print(coef_comp_reg.sort_values(by='Linear_Reg_Coef', ascending=False))\n",
    "\n",
    "# Variáveis excluídas (coeficiente = 0)\n",
    "excluded_vars_lasso = coef_comp_reg[coef_comp_reg['Lasso_Coef'].round(4) == 0]['Feature'].tolist()\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Efeito da Regularização Lasso:\")\n",
    "print(\"Lasso zera coeficientes de features irrelevantes (seleção automática de variáveis).\")\n",
    "if excluded_vars_lasso:\n",
    "    print(f\"Variáveis excluídas (Coeficiente ~ 0) pelo Lasso: {len(excluded_vars_lasso)} variáveis.\")\n",
    "else:\n",
    "    print(\"Nenhuma variável foi totalmente excluída com este alpha.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "08b0f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparação de Métricas de Regressão Contínua ---\n",
      "Regressão Linear Simples: R²=-4.5337\n",
      "Regressão Polinomial (Grau 2): R²=0.3890\n",
      "Avaliação: Houve melhora. O modelo Polinomial capturou melhor as relações não-lineares.\n"
     ]
    }
   ],
   "source": [
    "# Regressão Polinomial de Grau 2\n",
    "degree = 2\n",
    "poly = PolynomialFeatures(degree=degree, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_reg)\n",
    "X_test_poly = poly.transform(X_test_reg)\n",
    "\n",
    "# Modelo de Regressão Linear no novo conjunto\n",
    "poly_reg = LinearRegression()\n",
    "poly_reg.fit(X_train_poly, y_train_reg)\n",
    "y_pred_poly = poly_reg.predict(X_test_poly)\n",
    "\n",
    "# Métricas\n",
    "y_pred_lin = lin_reg.predict(X_test_reg)\n",
    "r2_lin = r2_score(y_test_reg, y_pred_lin)\n",
    "r2_poly = r2_score(y_test_reg, y_pred_poly)\n",
    "\n",
    "print(f\"\\n--- Comparação de Métricas de Regressão Contínua ---\")\n",
    "print(f\"Regressão Linear Simples: R²={r2_lin:.4f}\")\n",
    "print(f\"Regressão Polinomial (Grau {degree}): R²={r2_poly:.4f}\")\n",
    "\n",
    "# Avaliação\n",
    "if r2_poly > r2_lin:\n",
    "    print(\"Avaliação: Houve melhora. O modelo Polinomial capturou melhor as relações não-lineares.\")\n",
    "else:\n",
    "    print(\"Avaliação: Não houve melhora significativa ou o desempenho piorou, sugerindo que as relações são predominantemente lineares.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9b273a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparação de Desempenho: Árvore de Decisão vs. Random Forest ---\n",
      "                   Acurácia  F1-Score\n",
      "Modelo                               \n",
      "Árvore de Decisão       0.8  0.666667\n",
      "Random Forest           0.8  0.666667\n",
      "\n",
      "Discussão - Interpretabilidade e Desempenho:\n",
      "Árvore de Decisão: ALTA interpretabilidade (regras claras).\n",
      "Random Forest: Geralmente melhor desempenho, pois reduz a variância (mais estável), mas é um modelo mais 'caixa preta'.\n"
     ]
    }
   ],
   "source": [
    "# Função para avaliar Classificadores\n",
    "def evaluate_classifier(y_test, y_pred, model_name):\n",
    "    return {\n",
    "        'Modelo': model_name,\n",
    "        'Acurácia': accuracy_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred)\n",
    "    }\n",
    "\n",
    "# 1. Árvore de Decisão\n",
    "dt_model = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
    "dt_model.fit(X_train_class, y_train_class)\n",
    "metrics_dt = evaluate_classifier(y_test_class, dt_model.predict(X_test_class), 'Árvore de Decisão')\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=5)\n",
    "rf_model.fit(X_train_class, y_train_class)\n",
    "metrics_rf = evaluate_classifier(y_test_class, rf_model.predict(X_test_class), 'Random Forest')\n",
    "\n",
    "comparacao_tree = pd.DataFrame([metrics_dt, metrics_rf]).set_index('Modelo')\n",
    "\n",
    "print(\"\\n--- Comparação de Desempenho: Árvore de Decisão vs. Random Forest ---\")\n",
    "print(comparacao_tree)\n",
    "\n",
    "# Discussão\n",
    "print(\"\\nDiscussão - Interpretabilidade e Desempenho:\")\n",
    "print(\"Árvore de Decisão: ALTA interpretabilidade (regras claras).\")\n",
    "print(\"Random Forest: Geralmente melhor desempenho, pois reduz a variância (mais estável), mas é um modelo mais 'caixa preta'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "593bd8f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "--- Relatório Executivo - Comparação de Modelos ---\n",
      "\n",
      "Modelos de Classificação (Atraso na Entrega - Y_Binário):\n",
      "                Modelo  Acurácia  F1-Score\n",
      "0  Regressão Logística       0.8  0.666667\n",
      "1    Árvore de Decisão       0.8  0.666667\n",
      "2        Random Forest       0.8  0.666667\n",
      "3                  KNN       0.8  0.000000\n",
      "\n",
      "Modelos de Regressão Contínua (Consumo Real - Y_Contínuo):\n",
      "                Modelo        R²\n",
      "0  Polinomial (Grau 2)  0.389047\n",
      "1           Ridge (L2) -0.396367\n",
      "2           Lasso (L1) -0.959143\n",
      "3       Linear Simples -4.533694\n",
      "\n",
      "--- Recomendação Final ---\n",
      "Melhor Abordagem para o Desafio de Classificação (Atraso): **Regressão Logística**\n",
      "Justificativa:\n",
      "Recomendamos a Regressão Logística, pois, além do bom desempenho, ela oferece a **máxima interpretabilidade** para entender quais materiais/unidades mais contribuem para o risco de atraso (Odds Ratios). Isso é fundamental para a tomada de decisão operacional e intervenções.\n"
     ]
    }
   ],
   "source": [
    "# Consolidação de Métricas de Classificação\n",
    "all_class_metrics = pd.DataFrame([\n",
    "    evaluate_classifier(y_test_class, y_pred_knn, 'KNN'),\n",
    "    evaluate_classifier(y_test_class, y_pred_logreg, 'Regressão Logística'),\n",
    "    metrics_dt, metrics_rf\n",
    "])\n",
    "all_class_metrics = all_class_metrics.sort_values(by='F1-Score', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\\n--- Relatório Executivo - Comparação de Modelos ---\")\n",
    "\n",
    "print(\"\\nModelos de Classificação (Atraso na Entrega - Y_Binário):\")\n",
    "print(all_class_metrics)\n",
    "\n",
    "print(\"\\nModelos de Regressão Contínua (Consumo Real - Y_Contínuo):\")\n",
    "reg_metrics = pd.DataFrame({\n",
    "    'Modelo': ['Linear Simples', 'Ridge (L2)', 'Lasso (L1)', f'Polinomial (Grau {degree})'],\n",
    "    'R²': [r2_lin, r2_score(y_test_reg, ridge_model.predict(X_test_reg)), r2_score(y_test_reg, lasso_model.predict(X_test_reg)), r2_poly],\n",
    "})\n",
    "reg_metrics = reg_metrics.sort_values(by='R²', ascending=False).reset_index(drop=True)\n",
    "print(reg_metrics)\n",
    "\n",
    "# Recomendação Final\n",
    "best_class_model = all_class_metrics.iloc[0]\n",
    "\n",
    "print(\"\\n--- Recomendação Final ---\")\n",
    "print(f\"Melhor Abordagem para o Desafio de Classificação (Atraso): **{best_class_model['Modelo']}**\")\n",
    "print(\"Justificativa:\")\n",
    "if best_class_model['Modelo'] == 'Regressão Logística':\n",
    "    print(\"Recomendamos a Regressão Logística, pois, além do bom desempenho, ela oferece a **máxima interpretabilidade** para entender quais materiais/unidades mais contribuem para o risco de atraso (Odds Ratios). Isso é fundamental para a tomada de decisão operacional e intervenções.\")\n",
    "else:\n",
    "    print(f\"O **{best_class_model['Modelo']}** apresentou o melhor F1-Score/Acurácia. Ele é recomendado se o **desempenho preditivo bruto for a prioridade**, pois tende a ser mais robusto em dados complexos, mesmo que seja menos interpretável que a Regressão Logística.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
